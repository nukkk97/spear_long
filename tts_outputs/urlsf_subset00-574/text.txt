Reducing Reparameterization Gradient Variance May Nick Foti Alex DAmour Ryan Adams and just arxivd paper that focuses on reducing the variance of the reparameterization gradient estimator often used in the context of black box variational inference Ill give high level summary here but encourage you to check out the paper and the code Reparameterization Gradients Reparameterization gradients are often used when the objective of an optimization problem is written as an expectation common example is black box variational inference for approximating an intractable posterior distribution The objective we typically maximize is the evidence lower bound Using gradient based optimization requires computing the gradient with respect to which itself can be expressed as an expectation This expectation is in general analytically intractable but we can still use gradient based optimization if we can compute an unbiased estimate of the gradient such that The reparameterization gradient estimator is one such unbiased estimator The RGE uses the reparameterization trick to turn Monte Carlo ELBO estimator into Monte Carlo ELBO gradient estimator Recall that the reparameterization gradient estimator depends on differentiable map that transforms some seed randomness 
